{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module: src/ocr/image_preprocessor.py\n",
        "\n",
        "Converted from Python script to Jupyter Notebook format.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "\n",
        "class ImagePreprocessor:\n",
        "    def __init__(self):\n",
        "        self.tesseract_config = '--oem 3 --psm 6'\n",
        "\n",
        "    def preprocess_image(self, image_path):\n",
        "        \"\"\"\n",
        "        Preprocess image for better OCR results\n",
        "        \"\"\"\n",
        "        # Read image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(f\"Unable to load image from {image_path}\")\n",
        "\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply preprocessing steps\n",
        "        processed = self._enhance_image(gray)\n",
        "\n",
        "        return processed\n",
        "\n",
        "    def _enhance_image(self, gray_image):\n",
        "        \"\"\"\n",
        "        Apply various enhancement techniques to improve OCR accuracy\n",
        "        \"\"\"\n",
        "        # Noise reduction\n",
        "        denoised = cv2.fastNlMeansDenoising(gray_image)\n",
        "\n",
        "        # Increase contrast\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "        contrast_enhanced = clahe.apply(denoised)\n",
        "\n",
        "        # Morphological operations to clean up\n",
        "        kernel = np.ones((2,2), np.uint8)\n",
        "        cleaned = cv2.morphologyEx(contrast_enhanced, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "        # Threshold to binary\n",
        "        _, binary = cv2.threshold(cleaned, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        return binary\n",
        "\n",
        "    def extract_text(self, processed_image):\n",
        "        \"\"\"\n",
        "        Extract text from preprocessed image using OCR\n",
        "        \"\"\"\n",
        "        # Convert to PIL Image for pytesseract\n",
        "        pil_image = Image.fromarray(processed_image)\n",
        "\n",
        "        # Extract text\n",
        "        text = pytesseract.image_to_string(pil_image, config=self.tesseract_config)\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "    def extract_text_with_confidence(self, processed_image):\n",
        "        \"\"\"\n",
        "        Extract text with confidence scores\n",
        "        \"\"\"\n",
        "        pil_image = Image.fromarray(processed_image)\n",
        "\n",
        "        # Get detailed data including confidence scores\n",
        "        data = pytesseract.image_to_data(pil_image, output_type=pytesseract.Output.DICT)\n",
        "\n",
        "        # Filter out low confidence text\n",
        "        confident_text = []\n",
        "        for i, conf in enumerate(data['conf']):\n",
        "            if int(conf) > 50:  # Only keep text with >50% confidence\n",
        "                text = data['text'][i].strip()\n",
        "                if text:\n",
        "                    confident_text.append(text)\n",
        "\n",
        "        return ' '.join(confident_text)\n",
        "\n",
        "    def detect_code_regions(self, image_path):\n",
        "        \"\"\"\n",
        "        Detect potential code regions in the image\n",
        "        \"\"\"\n",
        "        image = cv2.imread(image_path)\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect horizontal lines (common in code editors)\n",
        "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))\n",
        "        horizontal_lines = cv2.morphologyEx(gray, cv2.MORPH_OPEN, horizontal_kernel)\n",
        "\n",
        "        # Find contours of potential code blocks\n",
        "        contours, _ = cv2.findContours(horizontal_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        code_regions = []\n",
        "        for contour in contours:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            if w > 100 and h > 20:  # Filter minimum size\n",
        "                code_regions.append((x, y, w, h))\n",
        "\n",
        "        return code_regions\n",
        "\n",
        "    def process_code_image(self, image_path):\n",
        "        \"\"\"\n",
        "        Complete pipeline to process a code screenshot\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Preprocess image\n",
        "            processed_image = self.preprocess_image(image_path)\n",
        "\n",
        "            # Extract text with confidence\n",
        "            extracted_text = self.extract_text_with_confidence(processed_image)\n",
        "\n",
        "            # Detect code regions\n",
        "            code_regions = self.detect_code_regions(image_path)\n",
        "\n",
        "            return {\n",
        "                'extracted_text': extracted_text,\n",
        "                'code_regions': code_regions,\n",
        "                'success': True\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'extracted_text': '',\n",
        "                'code_regions': [],\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    },
    "converted_at": "2025-11-12T20:34:46.493259Z"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}